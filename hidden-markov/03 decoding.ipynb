{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55636881",
   "metadata": {},
   "source": [
    "# Problem 2: Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5acea",
   "metadata": {},
   "source": [
    "* We have an HMM and we know the transition probabilities and observation likelihoods\n",
    "* Given an observation sequence, estimate the most likely hidden state sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11171c2",
   "metadata": {},
   "source": [
    "For any model that contains hidden variables, the task of determining which sequence of variable is the underlying source of some sequence of observations is called the **decoding** task.\n",
    "\n",
    "\n",
    "So in our example:\n",
    "\n",
    "\n",
    "Given a sequence of ice-cream observations *3 1 3* an an HMM, find the best hidden weather sequence (temp, temp, temp) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f38b3",
   "metadata": {},
   "source": [
    "This is easy with brute force: just check each possible sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0bf139",
   "metadata": {},
   "source": [
    "# Brute Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e00fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import forward_algorithm\n",
    "from markov import hot, cold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253ae99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72048514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(hot, hot, hot),\n",
       " (hot, hot, cold),\n",
       " (hot, cold, hot),\n",
       " (hot, cold, cold),\n",
       " (cold, hot, hot),\n",
       " (cold, hot, cold),\n",
       " (cold, cold, hot),\n",
       " (cold, cold, cold)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ALL_SEQUENCES = [\n",
    "    (t1,t2,t3)\n",
    "    for t1 in (hot, cold)\n",
    "    for t2 in (hot, cold)\n",
    "    for t3 in (hot, cold)\n",
    "]\n",
    "ALL_SEQUENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30af1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [3,1,3]\n",
    "o1,o2, o3 = observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023332a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coefficients import B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d4c49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Fraction(2, 25), (hot, cold, hot)),\n",
       " (Fraction(4, 125), (hot, hot, hot)),\n",
       " (Fraction(1, 50), (hot, cold, cold)),\n",
       " (Fraction(1, 50), (cold, cold, hot)),\n",
       " (Fraction(1, 125), (cold, hot, hot)),\n",
       " (Fraction(1, 125), (hot, hot, cold)),\n",
       " (Fraction(1, 200), (cold, cold, cold)),\n",
       " (Fraction(1, 500), (cold, hot, cold))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihoods = {\n",
    "    (\n",
    "        B[s1][o1] * B[s2][o2] * B[s3][o3],\n",
    "         (s1,s2,s3)\n",
    "         \n",
    "    )\n",
    "    for \n",
    "    (s1,s2,s3 ) in ALL_SEQUENCES\n",
    "\n",
    "}\n",
    " \n",
    "sorted(likelihoods, key = lambda pair:pair[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9209fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Fraction(2, 25), (hot, cold, hot))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87a11cf",
   "metadata": {},
   "source": [
    "So given the observation sequence `3,1,3` the mostly likely sequence of hidden states is `hot,cold,hot`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4154b903",
   "metadata": {},
   "source": [
    "Which is what we would expect. 'Ice cream consumption goes up on hot days'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc3430",
   "metadata": {},
   "source": [
    "#### Cost\n",
    "\n",
    "Again, this is comptutationally expensive.\n",
    "\n",
    "Instead we use the 'Virterbi Algorithm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7dec65",
   "metadata": {},
   "source": [
    "# Virterbi Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8090262c",
   "metadata": {},
   "source": [
    "> The idea is to process the observation sequence lef to right, filling out the trellis.\n",
    "\n",
    "> Each cell of the trellis, $v_t(j) represents the probability that the HMM is in state $j$ after seeing the first $t$ observations and passing through the most probable state sequence $q_1,...,q_{t-1}$, given the automaton $\\lambda$\n",
    "\n",
    "\n",
    "We compute values for each cell $v_t(j)$ by recursively taking the most probable path that could lead us to this cell.\n",
    "\n",
    "$$ \n",
    "\n",
    "    v_t(j) = \\max _{q_1,..., q_{t-1}} P(\n",
    "        q_1...q_{t-1},o_1, o_2...o_t , q_t = j | \\lambda)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90a347",
   "metadata": {},
   "source": [
    "Again, this can be done recursively\n",
    "\n",
    "\n",
    "$$\n",
    "    v_t(j) = \\max_{i=1}^N v_{t-1}(i) a_{ij} b_j (o_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2ee38",
   "metadata": {},
   "source": [
    "So the Virterbi probability at a time $t$ is a function of:\n",
    "\n",
    "* $v_{t-1}(i)$ - the virtebi value in a previous cell\n",
    "* $a_{ij}$ - the transition probability from that cell to this one\n",
    "* $b_j{o_t} $- the likelihood of observing symbol o_t given the current state $j$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5082a",
   "metadata": {},
   "source": [
    "> Note that the Virterbi algorithm is identical to the forward algorithm except that it takes `max` over previous path probability rather than `sum`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b5e648",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "markov",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
